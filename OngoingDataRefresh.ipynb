{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b27a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from arango import ArangoClient\n",
    "import subprocess\n",
    "import docker\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2659c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_data():\n",
    "    \n",
    "    client = ArangoClient(hosts='http://localhost:8529')\n",
    "    db = client.db('BlueBikesProject',username='root', password='root')\n",
    "\n",
    "    # Drop the collection if it exists\n",
    "    if db.has_collection('regions'):\n",
    "        db.delete_collection('regions')\n",
    "\n",
    "    if db.has_collection('stations'):\n",
    "        db.delete_collection('stations')\n",
    "    \n",
    "    if db.has_collection('station_status'):\n",
    "        db.delete_collection('station_status')\n",
    "    \n",
    "    # Defining the collections\n",
    "    region_col = db.create_collection('regions')\n",
    "    station_col = db.create_collection('stations')\n",
    "    status_col = db.create_collection('station_status')\n",
    "    \n",
    "    # Downloading the data from GBFS\n",
    "    \n",
    "    gbfs_url = 'https://gbfs.bluebikes.com/gbfs/gbfs.json'\n",
    "    gbfs_data = requests.get(gbfs_url).json()\n",
    "    \n",
    "    #fetching the URLs\n",
    "    \n",
    "    region_url = None\n",
    "    station_url = None\n",
    "    stationstatus_url = None\n",
    "    for feed in gbfs_data['data']['en']['feeds']:\n",
    "        if feed['name'] == 'system_regions':\n",
    "            region_url = feed['url']\n",
    "        elif feed['name'] == 'station_information':\n",
    "            station_url = feed['url']\n",
    "        elif feed['name'] == 'station_status':\n",
    "            stationstatus_url = feed['url']\n",
    "            \n",
    "    #fetching the data from the url\n",
    "    \n",
    "    responseRegions = requests.get(region_url).json()\n",
    "    regions = responseRegions['data']['regions']\n",
    "    #print(regions)\n",
    "    \n",
    "    responseStations = requests.get(station_url).json()\n",
    "    stations = responseStations['data']['stations']\n",
    "    #print(stations)\n",
    "    \n",
    "    responseStationStatus = requests.get(stationstatus_url).json()\n",
    "    stationstatus = responseStations['data']['stations']\n",
    "    #print(stationstatus)\n",
    "    \n",
    "    #Parsing into dataframes\n",
    "    regions_df = pd.DataFrame(regions)\n",
    "    stations_df = pd.DataFrame(stations)\n",
    "    station_status_df = pd.DataFrame(stationstatus)\n",
    "\n",
    "    #renaming the region_id and station_id columns in each dataframe to '_key' so that they act as documents in arangodb\n",
    "\n",
    "    regions_df = regions_df.rename(columns={'region_id': '_key'})\n",
    "    stations_df = stations_df.rename(columns={'station_id': '_key'})\n",
    "\n",
    "    #saving these dataframes as csv\n",
    "    \n",
    "    regions_df.to_csv('RegionsData.csv')\n",
    "    stations_df.to_csv('StationsData.csv')\n",
    "    station_status_df.to_csv('StationStatusData.csv')\n",
    "\n",
    "    #since I have installed arangodb using docker, using the docker container to run arangoimport command\n",
    "\n",
    "    client = docker.from_env()\n",
    "    container = client.containers.get('5aac08e9d503')\n",
    "\n",
    "    # create the tar archive of the csv files\n",
    "\n",
    "    stations_tar_file = tarfile.open('StationsData.tar.gz', 'w:gz')\n",
    "    stations_tar_file.add('StationsData.csv')\n",
    "    stations_tar_file.close()\n",
    "\n",
    "    regions_tar_file = tarfile.open('RegionsData.tar.gz', 'w:gz')\n",
    "    regions_tar_file.add('RegionsData.csv')\n",
    "    regions_tar_file.close()\n",
    "\n",
    "    stationstatus_tar_file = tarfile.open('StationStatusData.tar.gz', 'w:gz')\n",
    "    stationstatus_tar_file.add('StationStatusData.csv')\n",
    "    stationstatus_tar_file.close()\n",
    "\n",
    "    # copy the tar archives to the container\n",
    "    with open('StationsData.tar.gz', 'rb') as f:\n",
    "        container.put_archive('/Data/', f.read())\n",
    "    \n",
    "    with open('RegionsData.tar.gz', 'rb') as f:\n",
    "        container.put_archive('/Data/', f.read())\n",
    "    \n",
    "    with open('StationStatusData.tar.gz', 'rb') as f:\n",
    "        container.put_archive('/Data/', f.read())\n",
    "    \n",
    "    #running the arangoimport code for importing the trips data\n",
    "\n",
    "    cmdRegions = \"arangoimport --file RegionsData.csv --type csv --collection regions --server.endpoint tcp://{ip}:8529 --server.username root --server.password root --server.database BlueBikesProject\".format(ip=\"172.17.0.2\")\n",
    "    resultRegions = container.exec_run(cmdRegions)\n",
    "    print(resultRegions.output.decode())\n",
    "\n",
    "    cmdStations = \"arangoimport --file StationsData.csv --type csv --collection stations --server.endpoint tcp://{ip}:8529 --server.username root --server.password root --server.database BlueBikesProject\".format(ip=\"172.17.0.2\")\n",
    "    resultStations = container.exec_run(cmdStations)\n",
    "    print(resultStations.output.decode())\n",
    "\n",
    "    cmdStationStatus = \"arangoimport --file StationStatusData.csv --type csv --collection station_status --server.endpoint tcp://{ip}:8529 --server.username root --server.password root --server.database BlueBikesProject\".format(ip=\"172.17.0.2\")\n",
    "    resultStationStatus = container.exec_run(cmdStationStatus)\n",
    "    print(resultStationStatus.output.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e1ae5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ArangoDB 'http+tcp://172.17.0.2:8529, version: 3.10.4, database: 'BlueBikesProject', username: 'root'\n",
      "----------------------------------------\n",
      "database:               BlueBikesProject\n",
      "collection:             regions\n",
      "overwrite coll. prefix: no\n",
      "create:                 no\n",
      "create database:        no\n",
      "source filename:        RegionsData.csv\n",
      "file type:              csv\n",
      "quote:                  \"\n",
      "separator:              \n",
      "headers file:           \n",
      "threads:                4\n",
      "on duplicate:           error\n",
      "connect timeout:        5\n",
      "request timeout:        1200\n",
      "----------------------------------------\n",
      "Starting CSV import...\n",
      "\n",
      "created:          20\n",
      "warnings/errors:  0\n",
      "updated/replaced: 0\n",
      "ignored:          0\n",
      "lines read:       22\n",
      "\n",
      "Connected to ArangoDB 'http+tcp://172.17.0.2:8529, version: 3.10.4, database: 'BlueBikesProject', username: 'root'\n",
      "----------------------------------------\n",
      "database:               BlueBikesProject\n",
      "collection:             stations\n",
      "overwrite coll. prefix: no\n",
      "create:                 no\n",
      "create database:        no\n",
      "source filename:        StationsData.csv\n",
      "file type:              csv\n",
      "quote:                  \"\n",
      "separator:              \n",
      "headers file:           \n",
      "threads:                4\n",
      "on duplicate:           error\n",
      "connect timeout:        5\n",
      "request timeout:        1200\n",
      "----------------------------------------\n",
      "Starting CSV import...\n",
      "2023-04-11T21:41:04Z [807] INFO [9ddf3] {general} processed 79.4 KB (3%) of input file\n",
      "\n",
      "created:          453\n",
      "warnings/errors:  0\n",
      "updated/replaced: 0\n",
      "ignored:          0\n",
      "lines read:       455\n",
      "\n",
      "Connected to ArangoDB 'http+tcp://172.17.0.2:8529, version: 3.10.4, database: 'BlueBikesProject', username: 'root'\n",
      "----------------------------------------\n",
      "database:               BlueBikesProject\n",
      "collection:             station_status\n",
      "overwrite coll. prefix: no\n",
      "create:                 no\n",
      "create database:        no\n",
      "source filename:        StationStatusData.csv\n",
      "file type:              csv\n",
      "quote:                  \"\n",
      "separator:              \n",
      "headers file:           \n",
      "threads:                4\n",
      "on duplicate:           error\n",
      "connect timeout:        5\n",
      "request timeout:        1200\n",
      "----------------------------------------\n",
      "Starting CSV import...\n",
      "2023-04-11T21:41:04Z [819] INFO [9ddf3] {general} processed 79.4 KB (3%) of input file\n",
      "\n",
      "created:          453\n",
      "warnings/errors:  0\n",
      "updated/replaced: 0\n",
      "ignored:          0\n",
      "lines read:       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calling the function\n",
    "\n",
    "refresh_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
